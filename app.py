import streamlit as st
import pandas as pd
import folium
from streamlit_folium import st_folium
from geopy.geocoders import Nominatim
from geopy.extra.rate_limiter import RateLimiter
import openai
from openai import OpenAI
import fitz  # PyMuPDF
import os
import re
from pathlib import Path

# --- 1. ì´ˆê¸° ì„¤ì • ---

st.set_page_config(layout="wide")
st.title("ğŸ—ºï¸ ë¼í‹´ì•„ë©”ë¦¬ì¹´ ë‰´ìŠ¤ ê¸°ì‚¬ ì§€ë„ (PDF ê¸°ë°˜)")

try:
    # â˜ï¸ í´ë¼ìš°ë“œ ë°°í¬ ì‹œ ì´ st.secretsì—ì„œ í‚¤ë¥¼ ì½ì–´ì˜µë‹ˆë‹¤.
    openai_api_key = st.secrets["OPENAI_API_KEY"]
except:
    # ğŸ”’ ë¡œì»¬ í…ŒìŠ¤íŠ¸ìš© í‚¤ë¥¼ ë‹¤ì‹œ placeholderë¡œ ë³€ê²½!
    openai_api_key = "YOUR_OPENAI_API_KEY"

# (ìˆ˜ì •) ì´ ifë¬¸ì€ "YOUR_OPENAI_API_KEY"ë¼ëŠ” ê¸°ë³¸ ë¬¸ìì—´ê³¼ ë¹„êµí•´ì•¼ í•©ë‹ˆë‹¤.
if openai_api_key == "YOUR_OPENAI_API_KEY" or not openai_api_key:
    st.warning("OpenAI API í‚¤ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. 'ë” ì•Œì•„ë³´ê¸°' ê¸°ëŠ¥ì´ ì‘ë™í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.")
    client = None
else:
    client = OpenAI(api_key=openai_api_key)

# --- 2. (ìˆ˜ì •ë¨) ìˆ˜ë™ ìœ„ì¹˜ ìºì‹œ ---
# ë„¤íŠ¸ì›Œí¬ ë¬¸ì œë¡œ ì™¸ë¶€ ì„œë²„ ì ‘ì†ì´ ì•ˆë  ê²½ìš°ë¥¼ ëŒ€ë¹„í•œ ìˆ˜ë™ ì¢Œí‘œ ëª©ë¡
# (ì‹¤íŒ¨ ë¡œê·¸ì— ëœ¨ëŠ” ì§€ì—­ì´ ìˆë‹¤ë©´ ì—¬ê¸°ì— "ì§€ì—­ëª…": (ìœ„ë„, ê²½ë„) í˜•ì‹ìœ¼ë¡œ ì¶”ê°€í•˜ì„¸ìš”)
MANUAL_LOCATION_CACHE = {
    "í˜ë£¨, ë¦¬ë§ˆ, Plaza San MartÃ­n": (-12.0505, -77.0339),
    "í˜ë£¨, ë¦¬ë§ˆ": (-12.0464, -77.0428),
    "í˜ë£¨, ë¦¬ë§ˆ, Comas": (-11.9333, -77.0500),
    "í˜ë£¨, ë¦¬ë§ˆ & Callao": (-12.0464, -77.0428),  # CallaoëŠ” ë¦¬ë§ˆ ê·¼ì²˜ì´ë¯€ë¡œ ë¦¬ë§ˆ ì¢Œí‘œ ì‚¬ìš©
    "ë³¼ë¦¬ë¹„ì•„, ë¼íŒŒìŠ¤": (-16.4897, -68.1193),
    "ì•„ë¥´í—¨í‹°ë‚˜": (-38.4161, -63.6167),
    "ë„ë¯¸ë‹ˆì¹´ê³µí™”êµ­": (18.7357, -70.1627),
    "ë¯¸êµ­, ì½œë¡œë¼ë„, Aurora": (39.7294, -104.8319),
    # í•„ìš”ì‹œ ê³„ì† ì¶”ê°€...
}


# --- 3. PDF íŒŒì‹± ë° ë°ì´í„° ë¡œë”© í•¨ìˆ˜ (ì´ì „ê³¼ ë™ì¼) ---

def parse_pdf_text(text):
    data = {}

    def extract_field(field_name, text_block):
        pattern_csv = rf'"[^"]*"\s*,\s*"{re.escape(field_name)}"\s*,\s*"([^"]*)"'
        match_csv = re.search(pattern_csv, text_block)
        if match_csv: return match_csv.group(1).strip().strip('""')
        pattern_newline = rf'\n\d{{1,2}}\n{re.escape(field_name)}\n(.*?)(?=\n\d{{1,2}}\n)'
        match_newline = re.search(pattern_newline, text_block, re.DOTALL)
        if match_newline: return re.sub(r'\s*\n\s*', ' ', match_newline.group(1)).strip()
        return "ì •ë³´ ì—†ìŒ"

    data['ëŒ€ë¶„ë¥˜'] = extract_field("ê°ˆë“± ëŒ€ë¶„ë¥˜", text)
    data['ì¤‘ë¶„ë¥˜'] = extract_field("ê°ˆë“± ì¤‘ë¶„ë¥˜", text)
    data['ì†Œë¶„ë¥˜'] = extract_field("ê°ˆë“± ì†Œë¶„ë¥˜", text)
    data['ì§€ì—­ì •ë³´'] = extract_field("ìœ„ì¹˜", text)
    data['ê¸°ì‚¬ì œëª©'] = extract_field("ì œëª©", text)
    data['ì´ë²¤íŠ¸'] = extract_field("ë³´ë„ ì¼ì", text)
    url = "ë§í¬ ì—†ìŒ";
    url_key_match_csv = re.search(r'"ì¶œì²˜\(URL\)"', text)
    if url_key_match_csv:
        text_after_key = text[url_key_match_csv.end():];
        url_match = re.search(r'(https?://[^\s)]+)', text_after_key)
        if url_match: url = url_match.group(1).strip().strip(')"')
    if url == "ë§í¬ ì—†ìŒ":
        pattern_newline_url = r'\n12\nì¶œì²˜\(URL\)\n[^\n]*\n\((https?://[^\)]+)\)';
        match_newline_url = re.search(pattern_newline_url, text, re.DOTALL)
        if match_newline_url: url = match_newline_url.group(1).strip()
    data['ê¸°ì‚¬ë§í¬'] = url
    summary = "ìš”ì•½ ì •ë³´ ì—†ìŒ";
    summary_match_peru = re.search(r'\n15\nê¸°ì‚¬ í…ìŠ¤íŠ¸\s*\([^\)]+\)\n(.*?)(?=\n[A-ZÃ€-Ã¿][a-z])', text, re.DOTALL)
    if summary_match_peru: summary = re.sub(r'\s*\n\s*', ' ', summary_match_peru.group(1).strip())
    if summary == "ìš”ì•½ ì •ë³´ ì—†ìŒ":
        summary_match_arg = re.search(r'"ê´€ë ¨ ì´ë²¤íŠ¸"\s*,\s*,(.*?)(?=\n"\d{1,2}"\s*,|\n,,"ê¸°ì‚¬ í…ìŠ¤íŠ¸")', text, re.DOTALL)
        if summary_match_arg: summary = re.sub(r'^\s*,,', '', summary_match_arg.group(1),
                                               flags=re.MULTILINE).strip().strip('"')
    data['ìš”ì•½'] = summary;
    data['ë²ˆì—­'] = summary
    for key, value in data.items():
        if not value: data[key] = "ì •ë³´ ì—†ìŒ"
    return data


@st.cache_data
def load_data_from_pdfs(folder_path="sampledata"):
    all_articles = [];
    data_folder = Path(folder_path);
    first_pdf_text = None
    if not data_folder.exists() or not data_folder.is_dir():
        st.error(f"'{folder_path}' í´ë”ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.");
        return pd.DataFrame(), None
    pdf_files = list(data_folder.glob("*.pdf"))
    if not pdf_files: st.error(f"'{folder_path}' í´ë”ì— PDF íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤."); return pd.DataFrame(), None
    progress_bar = st.progress(0, text="PDF íŒŒì¼ ë¡œë”© ì¤‘...")
    for i, pdf_path in enumerate(pdf_files):
        try:
            doc = fitz.open(pdf_path);
            full_text = "".join(page.get_text("text", sort=False) for page in doc);
            doc.close()
            if i == 0: first_pdf_text = full_text
            article_data = parse_pdf_text(full_text);
            article_data['filename'] = pdf_path.name;
            all_articles.append(article_data)
            progress_bar.progress((i + 1) / len(pdf_files), text=f"PDF íŒŒì¼ ë¡œë”© ì¤‘: {pdf_path.name}")
        except Exception as e:
            st.warning(f"'{pdf_path.name}' íŒŒì¼ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
    progress_bar.empty()
    if not all_articles: return pd.DataFrame(), first_pdf_text
    df = pd.DataFrame(all_articles);
    required_cols = ['ëŒ€ë¶„ë¥˜', 'ì¤‘ë¶„ë¥˜', 'ì†Œë¶„ë¥˜', 'ì§€ì—­ì •ë³´', 'ê¸°ì‚¬ì œëª©', 'ì´ë²¤íŠ¸', 'ë²ˆì—­', 'ìš”ì•½'];
    all_cols_valid = True
    for col in required_cols:
        if col not in df.columns:
            df[col] = "ì •ë³´ ì—†ìŒ"; all_cols_valid = False
        elif (df[col] == "ì •ë³´ ì—†ìŒ").all() or df[col].isnull().all():
            all_cols_valid = False
    if not all_cols_valid: return df, first_pdf_text
    return df, None


# --- 4. (ìˆ˜ì •ë¨) ì§€ì˜¤ì½”ë”© ì„¤ì • ---

geolocator = Nominatim(user_agent="Mozilla/5.0")
geocode = RateLimiter(geolocator.geocode, min_delay_seconds=1)


@st.cache_data
def get_lat_lon(location_str):
    if location_str == "ì •ë³´ ì—†ìŒ" or not location_str:
        return None, None

    # 1. (ì¶”ê°€) ìˆ˜ë™ ìºì‹œì—ì„œ ë¨¼ì € ì°¾ê¸°
    if location_str in MANUAL_LOCATION_CACHE:
        return MANUAL_LOCATION_CACHE[location_str]

    # 2. ìˆ˜ë™ ìºì‹œì— ì—†ìœ¼ë©´, ë„¤íŠ¸ì›Œí¬ ì ‘ì† ì‹œë„ (ì—¬ì „íˆ ì‹¤íŒ¨í•  ìˆ˜ ìˆìŒ)
    clean_str = re.sub(r'\s*&.*', '', location_str).strip()
    try:
        location = geocode(clean_str, timeout=20)
        if location:
            return location.latitude, location.longitude
        else:
            if clean_str != location_str:
                location_original = geocode(location_str, timeout=20)
                if location_original:
                    return location_original.latitude, location_original.longitude
            print(f"Geocoding (Fallback): Location not found for '{location_str}'")
    except Exception as e:
        print(f"Geocoding (Fallback) Error for '{location_str}': {e}")

    # 3. (ì¶”ê°€) ìˆ˜ë™ ìºì‹œì— ì—†ëŠ” ì§€ì—­ì´ ì‹¤íŒ¨í•  ê²½ìš°, í•´ë‹¹ ì§€ì—­ì˜ "êµ­ê°€ëª…"ë§Œìœ¼ë¡œ ì¬ì‹œë„
    # ì˜ˆ: "í˜ë£¨, ë¦¬ë§ˆ, Cieneguilla" -> "í˜ë£¨"
    try:
        country_name = location_str.split(',')[0].strip()
        if country_name in MANUAL_LOCATION_CACHE:  # êµ­ê°€ëª…ì´ ìºì‹œì— ìˆë‹¤ë©´
            return MANUAL_LOCATION_CACHE[country_name]

        # êµ­ê°€ëª…ìœ¼ë¡œ ë‹¤ì‹œ ë„¤íŠ¸ì›Œí¬ ì‹œë„
        location_country = geocode(country_name, timeout=20)
        if location_country:
            # êµ­ê°€ëª… ì¢Œí‘œë¼ë„ ë°˜í™˜
            return location_country.latitude, location_country.longitude
    except Exception as e:
        print(f"Geocoding (Country Fallback) Error for '{country_name}': {e}")

    return None, None  # ëª¨ë“  ì‹œë„ ì‹¤íŒ¨


# --- 5. ë©”ì¸ ì• í”Œë¦¬ì¼€ì´ì…˜ ì‹¤í–‰ ---

df, debug_text = load_data_from_pdfs("sampledata")

if debug_text:
    st.error("ë°ì´í„° íŒŒì‹±ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤. íŒŒì‹± ë¡œì§ì´ PDF êµ¬ì¡°ì™€ ë§ëŠ”ì§€ í™•ì¸í•´ì£¼ì„¸ìš”.")
    st.subheader("ë””ë²„ê¹… ì •ë³´: ì²« ë²ˆì§¸ PDF ì¶”ì¶œ ì›ë³¸ í…ìŠ¤íŠ¸ (ì¼ë¶€)")
    st.text_area("Raw Text", debug_text[:2000], height=300)
    for col in ['ëŒ€ë¶„ë¥˜', 'ì¤‘ë¶„ë¥˜', 'ì†Œë¶„ë¥˜', 'ì§€ì—­ì •ë³´', 'ê¸°ì‚¬ì œëª©', 'ì´ë²¤íŠ¸', 'ìš”ì•½']:
        if col not in df or (df[col] == "ì •ë³´ ì—†ìŒ").all() or df[col].isnull().all():
            st.warning(f"ê²½ê³ : '{col}' ì»¬ëŸ¼ì˜ ìœ íš¨í•œ ë°ì´í„°ë¥¼ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.")

elif df.empty or (df['ì§€ì—­ì •ë³´'] == "ì •ë³´ ì—†ìŒ").all():
    st.error("ë°ì´í„° ë¡œë”©ì— ì‹¤íŒ¨í–ˆê±°ë‚˜ ìœ íš¨í•œ 'ì§€ì—­ì •ë³´'ë¥¼ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤. ì•±ì„ ì‹¤í–‰í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
else:
    st.success(f"ì´ {len(df)}ê°œì˜ PDF ê¸°ì‚¬ë¥¼ ì„±ê³µì ìœ¼ë¡œ ë¡œë“œí•˜ê³  íŒŒì‹±í–ˆìŠµë‹ˆë‹¤.")

    keyword = st.text_input("í‚¤ì›Œë“œë¥¼ ì…ë ¥í•˜ì„¸ìš” (ì˜ˆ: í˜ë£¨, ì¸í”Œë ˆì´ì…˜, ë¦¬ë§ˆ ë“±)", "")

    if keyword:
        df_searchable = df[(df['ëŒ€ë¶„ë¥˜'] != "ì •ë³´ ì—†ìŒ") & (df['ì§€ì—­ì •ë³´'] != "ì •ë³´ ì—†ìŒ")]
        mask = (
                df_searchable['ëŒ€ë¶„ë¥˜'].str.contains(keyword, case=False, na=False) |
                df_searchable['ì¤‘ë¶„ë¥˜'].str.contains(keyword, case=False, na=False) |
                df_searchable['ì†Œë¶„ë¥˜'].str.contains(keyword, case=False, na=False) |
                df_searchable['ê¸°ì‚¬ì œëª©'].str.contains(keyword, case=False, na=False) |
                df_searchable['ì§€ì—­ì •ë³´'].str.contains(keyword, case=False, na=False)
        )
        filtered_df = df_searchable[mask].copy()

        if filtered_df.empty:
            st.warning("ê²€ìƒ‰ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤.")
        else:
            st.info("ê²€ìƒ‰ëœ ì§€ì—­ì˜ ì¢Œí‘œë¥¼ ë³€í™˜ ì¤‘ì…ë‹ˆë‹¤...")
            geocoding_placeholder = st.empty()
            log_messages = []

            unique_locations = filtered_df['ì§€ì—­ì •ë³´'].unique()
            total_locations = len(unique_locations)
            location_cache = {}

            progress_bar = st.progress(0, text="ì¢Œí‘œ ë³€í™˜ ì‹œì‘...")

            for i, location_str in enumerate(unique_locations):
                progress_bar.progress((i + 1) / total_locations, text=f"ë³€í™˜ ì¤‘: {location_str}")

                lat, lon = get_lat_lon(location_str)  # ìˆ˜ì •ëœ ìºì‹œ ìš°ì„  í•¨ìˆ˜ í˜¸ì¶œ
                location_cache[location_str] = (lat, lon)

                if lat is not None:
                    log_messages.append(f"âœ… **[ì„±ê³µ]** `{location_str}` -> `({lat:.4f}, {lon:.4f})`")
                else:
                    log_messages.append(f"âŒ **[ì‹¤íŒ¨]** `{location_str}` -> ìˆ˜ë™ ìºì‹œì— ì—†ìœ¼ë©°, ë„¤íŠ¸ì›Œí¬ ì ‘ì†ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.")

                geocoding_placeholder.expander("ì¢Œí‘œ ë³€í™˜ ë¡œê·¸ ë³´ê¸°", expanded=True).markdown("\n".join(log_messages))

            progress_bar.empty()

            coords = filtered_df['ì§€ì—­ì •ë³´'].map(location_cache)
            filtered_df['latitude'] = [c[0] for c in coords]
            filtered_df['longitude'] = [c[1] for c in coords]

            filtered_df.dropna(subset=['latitude', 'longitude'], inplace=True)

            if filtered_df.empty:
                st.warning("í‚¤ì›Œë“œì— í•´ë‹¹í•˜ëŠ” ê¸°ì‚¬ëŠ” ìˆìœ¼ë‚˜, ì§€ë„ì— í‘œì‹œí•  ìœ„ì¹˜ ì •ë³´ë¥¼ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤. (ìœ„ì˜ 'ì¢Œí‘œ ë³€í™˜ ë¡œê·¸'ë¥¼ í™•ì¸í•˜ì—¬ ëª¨ë“  ìœ„ì¹˜ê°€ âŒ[ì‹¤íŒ¨]í–ˆëŠ”ì§€ í™•ì¸í•˜ì„¸ìš”.)")
            else:
                geocoding_placeholder.empty()

                # 6. Folium ì§€ë„ ì‹œê°í™”
                m = folium.Map(location=[filtered_df['latitude'].mean(), filtered_df['longitude'].mean()], zoom_start=4)
                color_map = {'êµ­ë‚´(ì‚¬íšŒ)': 'red', 'êµ­ë‚´(ê²½ì œ)': 'green', 'êµ­ë‚´(ë²”ì£„)': 'black', 'êµ­ì œ(êµ­ì œê´€ê³„)': 'purple', 'ì •ì¹˜': 'blue'}
                for idx, row in filtered_df.iterrows():
                    popup_html = f"""
                    <h4>{row['ê¸°ì‚¬ì œëª©']}</h4>
                    <b>ì‹œê°„:</b> {row['ì´ë²¤íŠ¸']}<br>
                    <b>ë¶„ë¥˜:</b> {row['ëŒ€ë¶„ë¥˜']} > {row['ì¤‘ë¶„ë¥˜']} > {row['ì†Œë¶„ë¥˜']}<br>
                    <a href="{row['ê¸°ì‚¬ë§í¬']}" target="_blank">ê¸°ì‚¬ ì›ë¬¸ ë³´ê¸°</a>
                    <hr>
                    <div id="details_{idx}" style="display:none; max-height: 150px; overflow-y: auto;">
                        <b>ìš”ì•½:</b><p>{row['ìš”ì•½']}</p>
                    </div>
                    <button onclick="
                        var el = document.getElementById('details_{idx}');
                        if (el.style.display == 'none') {{
                            el.style.display = 'block'; this.textContent = 'ìš”ì•½ ë‹«ê¸°';
                        }} else {{
                            el.style.display = 'none'; this.textContent = 'ìš”ì•½ ë³´ê¸°';
                        }}
                    ">ìš”ì•½ ë³´ê¸°</button>
                    """
                    iframe = folium.IFrame(popup_html, width=350, height=250)
                    popup = folium.Popup(iframe, max_width=350)
                    folium.Marker(
                        location=[row['latitude'], row['longitude']],
                        popup=popup,
                        icon=folium.Icon(color=color_map.get(row['ëŒ€ë¶„ë¥˜'], 'gray')),
                        tooltip=row['ê¸°ì‚¬ì œëª©']
                    ).add_to(m)

                st.subheader(f"'{keyword}' ê²€ìƒ‰ ê²°ê³¼: {len(filtered_df)}ê°œ")
                st_folium(m, width='100%', height=500)

                # 7. OpenAI API ì—°ë™
                st.markdown("---")
                if st.button("ğŸ¤– AIë¡œ ìœ ì‚¬ ê¸°ì‚¬ ë” ì•Œì•„ë³´ê¸°"):
                    if not client:
                        st.error("OpenAI API í‚¤ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
                    else:
                        with st.spinner("AIê°€ ìœ ì‚¬í•œ ê¸°ì‚¬ë¥¼ ì°¾ê³  ìˆìŠµë‹ˆë‹¤..."):
                            context_articles = "\n".join(
                                [f"- ì œëª©: {row['ê¸°ì‚¬ì œëª©']}, ìš”ì•½: {row['ìš”ì•½']}" for _, row in filtered_df.iterrows()])
                            prompt = f"""
                            ë‹¹ì‹ ì€ ë¼í‹´ì•„ë©”ë¦¬ì¹´ ì „ë¬¸ ë‰´ìŠ¤ íë ˆì´í„°ì…ë‹ˆë‹¤.
                            ì•„ë˜ëŠ” ì‚¬ìš©ìê°€ ë°©ê¸ˆ '{keyword}' í‚¤ì›Œë“œë¡œ ê²€ìƒ‰í•œ ë‰´ìŠ¤ ê¸°ì‚¬ ëª©ë¡ì…ë‹ˆë‹¤.
                            <ê¸°ì¡´ ê¸°ì‚¬ ëª©ë¡>
                            {context_articles}
                            </ê¸°ì¡´ ê¸°ì‚¬ ëª©ë¡>
                            ìœ„ ê¸°ì‚¬ë“¤ê³¼ ì£¼ì œ, ì§€ì—­, ë‚´ìš© ë©´ì—ì„œ ìœ ì‚¬í•œ ìµœì‹  ê¸°ì‚¬ 3ê°œë¥¼ ì°¾ì•„ì„œ ì œì‹œí•´ì£¼ì„¸ìš”.
                            ê° ê¸°ì‚¬ë§ˆë‹¤ ì•„ë˜ì™€ ê°™ì€ í˜•ì‹ìœ¼ë¡œ ë‹µë³€í•´ì£¼ì„¸ìš”.
                            - **ê¸°ì‚¬ ì œëª©:** [ìƒˆë¡œìš´ ê¸°ì‚¬ì˜ ì œëª©]
                            - **ê¸°ì‚¬ ë§í¬:** [ì‹¤ì œ ë§í¬ê°€ ì•„ë‹Œ ì˜ˆì‹œ ë§í¬ (ì˜ˆ: http://example.com/news/123)]
                            - **ë²ˆì—­ ë° ìš”ì•½:** [ìƒˆë¡œìš´ ê¸°ì‚¬ì— ëŒ€í•œ ê°„ëµí•œ 'ë²ˆì—­ ë° ìš”ì•½]
                            ---
                            """
                            try:
                                response = client.chat.completions.create(
                                    model="gpt-4o",
                                    messages=[
                                        {"role": "system",
                                         "content": "You are a helpful assistant specializing in Latin American news."},
                                        {"role": "user", "content": prompt}
                                    ]
                                )
                                result_text = response.choices[0].message.content
                                st.subheader("AI ì¶”ì²œ ìœ ì‚¬ ê¸°ì‚¬")
                                st.markdown(result_text)
                            except Exception as e:
                                st.error(f"API í˜¸ì¶œ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {e}")